"""
# neural network structure from https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html
self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)
self.bn1 = nn.BatchNorm2d(16)
self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)
self.bn2 = nn.BatchNorm2d(32)
self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)
self.bn3 = nn.BatchNorm2d(32)

# Number of Linear input connections depends on output of conv2d layers
# and therefore the input image size, so compute it.
def conv2d_size_out(size, kernel_size=5, stride=2):
    return (size - (kernel_size - 1) - 1) // stride + 1

convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(state_space_size.shape[0])))
convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(state_space_size.shape[1])))
linear_input_size = convw * convh * 32

self.final_layer = nn.Linear(linear_input_size, action_space_size)
"""

next_state_values = torch.zeros(self.batch_size)
next_state_values[non_final_mask] = torch.max(self.Q_target.forward(s_next), axis=1).values.detach()